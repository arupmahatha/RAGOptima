{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGBuilder Optimization Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First clone the RAGBuilder repo\n",
    "!uv pip install ragbuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart - Basic Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragbuilder import RAGBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "llm=AzureChatOpenAI(model='gpt-4o-mini', temperature=0.2)\n",
    "emb=AzureOpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = RAGBuilder.from_source_with_defaults(\n",
    "    input_source='https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
    "    test_dataset=\"rag_test_data_lilianweng_gpt-4o_1721032414.736622.csv\",\n",
    "    default_llm=llm,\n",
    "    default_embeddings=emb,\n",
    "    n_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f939e588feb84039b090f17ae858ca19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting Data Ingestion Optimization...</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting Data Ingestion Optimization\u001b[0m\u001b[1;38;5;27m...\u001b[0m\u001b[92m ─────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:39,355] A new study created in RDB with name: data_ingest_1735663839280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2252d49b76f43e5b54ce279f6b726de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d75c0dfb52a4d1da2495c8cac0f7969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.8156</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.8156\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:47,057] Trial 0 finished with value: 0.8156415328383447 and parameters: {'chunk_size': 1000}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7929</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7929\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:50,786] Trial 1 finished with value: 0.7929137279589971 and parameters: {'chunk_size': 3000}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bed8e5c8105401b8f460ac5220805db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7926</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7926\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:56,317] Trial 2 finished with value: 0.7926271418730417 and parameters: {'chunk_size': 2500}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:20:56] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7926271418730417</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:20:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.7926271418730417\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:56,336] Trial 3 finished with value: 0.7926271418730417 and parameters: {'chunk_size': 2500}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7929137279589971</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.7929137279589971\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:56,351] Trial 4 finished with value: 0.7929137279589971 and parameters: {'chunk_size': 3000}. Best is trial 0 with value: 0.8156415328383447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Optimization Complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mOptimization Complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.8156</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Best Parameters:</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">'chunk_size'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">1000</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m0.8156\u001b[0m\n",
       "\u001b[32mBest Parameters:\u001b[0m\n",
       "\u001b[1;96m{\u001b[0m\u001b[96m'chunk_size'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m1000\u001b[0m\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Successfully optimized and cached best configuration</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Successfully optimized and cached best configuration\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:20:59] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736622.</span>csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:20:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.\u001b[1;36m736622.\u001b[0mcsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting retriever optimization...</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting retriever optimization\u001b[0m\u001b[1;38;5;27m...\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:20:59,424] A new study created in RDB with name: retriever_1735663859509\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fe94e1ab54465e96f34372d615616d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2858c774ef944c5e95b0df92d2e964f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:10,368] Trial 0 finished with value: 0.9999999999716667 and parameters: {'n_retrievers': 1, 'retriever_0_index': 0, 'final_k': 5}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb37dba9a8504012adefcc1f7a69bd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.941</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.889</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m0.941\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m0.889\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:17,823] Trial 1 finished with value: 0.9411764705636293 and parameters: {'n_retrievers': 2, 'retriever_0_index': 1, 'retriever_1_index': 0, 'final_k': 3}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f3d7b094604df695641239a7453ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.875</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.778</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m0.875\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m0.778\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:25,303] Trial 2 finished with value: 0.8749999999702256 and parameters: {'n_retrievers': 1, 'retriever_0_index': 1, 'final_k': 3}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623acd1135c44c93ab658812f9399db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.941</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.889</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m0.941\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m0.889\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:32,750] Trial 3 finished with value: 0.9411764705611687 and parameters: {'n_retrievers': 1, 'retriever_0_index': 0, 'final_k': 3}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8749999999702256</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.8749999999702256\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:21:32,770] Trial 4 finished with value: 0.8749999999702256 and parameters: {'n_retrievers': 1, 'retriever_0_index': 1, 'final_k': 3}. Best is trial 0 with value: 0.9999999999716667.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">✓ Optimization complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27m✓ Optimization complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">1.0000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m1.0000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Configuration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'retrievers'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'vector_similarity'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">]</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'top_k'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'rerankers'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'BAAI/bge-reranker-base'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">]}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;96m{\u001b[0m\u001b[32m'retrievers'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m[\u001b[0m\u001b[32m'vector_similarity'\u001b[0m\u001b[1;96m]\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'top_k'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'rerankers'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m[\u001b[0m\u001b[32m'BAAI/bge-reranker-base'\u001b[0m\u001b[1;96m]\u001b[0m\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:34] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736622.</span>csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.\u001b[1;36m736622.\u001b[0mcsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting Generation Optimization</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting Generation Optimization\u001b[0m\u001b[92m ─────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> trial configurations                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generated \u001b[1;36m5\u001b[0m trial configurations                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m0\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m0\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:41] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m1\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m1\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:46] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m2\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m2\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m3\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m3\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:21:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:21:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m4\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m4\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2cc7a08d2d437a9fe086a69d434ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:22:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Evaluating prompt results                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:22:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Evaluating prompt results                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8693af6631e4ea7bb83c170766a04c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:22:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Calculating final prompt testing results                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:22:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Calculating final prompt testing results                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Average correctness results saved to <span style=\"color: #008000; text-decoration-color: #008000\">'rag_average_correctness_20241231_222242.csv'</span>             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Average correctness results saved to \u001b[32m'rag_average_correctness_20241231_222242.csv'\u001b[0m             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Optimization Complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mOptimization Complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7404</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m0.7404\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Configuration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'AzureChatOpenAI:gpt-4o-mini'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">,</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">,</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_template'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a highly accurate assistant. Respond only with the facts found in the provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context. \\nIf there is insufficient information in the context, say \"I don\\'t </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">know.\"\\n\\n&lt;context&gt;\\n{context}\\n&lt;/context&gt;\\n'</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;96m{\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'model'\u001b[0m\u001b[96m: \u001b[0m\u001b[32m'AzureChatOpenAI:gpt-4o-mini'\u001b[0m\u001b[96m,\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'temperature'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[96m,\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'prompt_template'\u001b[0m\u001b[96m: \u001b[0m\u001b[32m'You are a highly accurate assistant. Respond only with the facts found in the provided \u001b[0m\n",
       "\u001b[32mcontext. \\nIf there is insufficient information in the context, say \"I don\\'t \u001b[0m\n",
       "\u001b[32mknow.\"\\n\\n\u001b[0m\u001b[32m<\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m>\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n</context\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n'\u001b[0m\n",
       "\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results =builder.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = results.invoke(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is HNSW?\n",
      "Answer: HNSW (Hierarchical Navigable Small World) is a data structure inspired by small world networks, where most nodes can be reached from any other node within a small number of steps. It builds hierarchical layers of small-world graphs, with the bottom layers containing actual data points. The middle layers create shortcuts to speed up search. During a search, HNSW starts from a random node in the top layer and navigates towards the target, moving down layers until it reaches the bottom layer. Moves in the upper layers can cover large distances in the data space, while moves in the lower layers refine the search quality.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {response['question']}\\nAnswer: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_ingest\": {\n",
      "    \"score\": 0.8156415328383447,\n",
      "    \"optimization_time\": 16.987402,\n",
      "    \"config\": {\n",
      "      \"document_loader\": \"unstructured\",\n",
      "      \"chunking_strategy\": \"RecursiveCharacterTextSplitter\",\n",
      "      \"chunk_size\": 1000,\n",
      "      \"chunk_overlap\": 100,\n",
      "      \"embedding_model\": \"EmbeddingType.HUGGINGFACE:mixedbread-ai/mxbai-embed-large-v1\",\n",
      "      \"vector_database\": \"chroma\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": 127.93433333333333,\n",
      "      \"error_rate\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"retrieval\": {\n",
      "    \"score\": 0.9999999999716667,\n",
      "    \"optimization_time\": 33.336164,\n",
      "    \"config\": {\n",
      "      \"retrievers\": [\n",
      "        \"vector_similarity\"\n",
      "      ],\n",
      "      \"top_k\": 5,\n",
      "      \"rerankers\": [\n",
      "        \"BAAI/bge-reranker-base\"\n",
      "      ]\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": 451.14433333333335,\n",
      "      \"error_rate\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"generation\": {\n",
      "    \"score\": 0.7403833697261465,\n",
      "    \"optimization_time\": 68.449513,\n",
      "    \"config\": {\n",
      "      \"model\": \"AzureChatOpenAI:gpt-4o-mini\",\n",
      "      \"temperature\": 0.2,\n",
      "      \"prompt_template\": \"You are a highly accurate assistant. Respond only with the facts found in the provided context. \\nIf there is insufficient information in the context, say \\\"I don't know.\\\"\\n\\n<context>\\n{context}\\n</context>\\n\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": null,\n",
      "      \"error_rate\": null\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(results.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install pymupdf pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_builder = RAGBuilder(\n",
    "    default_llm=llm,\n",
    "    default_embeddings=emb,\n",
    "    n_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragbuilder.config import (\n",
    "    DataIngestOptionsConfig,\n",
    "    RetrievalOptionsConfig,\n",
    "    GenerationOptionsConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a data ingestion configuration with more options (Eg: multiple parsers/loaders, knowledge graph, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingest_config = DataIngestOptionsConfig(\n",
    "    input_source=\"lillog_agents.pdf\",\n",
    "    document_loaders=[\n",
    "        {\"type\": \"pymupdf\"},\n",
    "        {\"type\": \"unstructured\"},\n",
    "        {\"type\": \"pypdf\"}\n",
    "    ],\n",
    "    chunking_strategies=[\n",
    "        {\n",
    "            \"type\": \"RecursiveCharacterTextSplitter\",\n",
    "            \"chunker_kwargs\": {\"separators\": [\"\\n\\n\", \"\\n\", \" \", \"\"]}\n",
    "        }\n",
    "    ],\n",
    "    chunk_size={\n",
    "        \"min\": 500,\n",
    "        \"max\": 3000,\n",
    "        \"stepsize\": 500\n",
    "    },\n",
    "    chunk_overlap=[100],\n",
    "    embedding_models=[\n",
    "        {\n",
    "            \"type\": \"azure_openai\",\n",
    "            \"model_kwargs\": {\n",
    "                \"model\": \"text-embedding-3-large\",\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    vector_databases=[\n",
    "        {\n",
    "            \"type\": \"chroma\",\n",
    "            \"vectordb_kwargs\": {\n",
    "                'persist_directory': 'chroma_sample2123',\n",
    "                'collection_metadata': {'hnsw:space': 'cosine'}\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    graph={\n",
    "        \"type\": \"neo4j\", # Note that you will need to have a neo4j instance running. \n",
    "                         # There's a docker compose file in the repo.\n",
    "                         # You will also need to set the NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD environment variables.\n",
    "    },\n",
    "    optimization={\n",
    "        \"n_trials\": 10,\n",
    "        \"n_jobs\": 1,\n",
    "        \"study_name\": \"lillog_agents_study\",\n",
    "        \"optimization_direction\": \"maximize\"\n",
    "    },\n",
    "    evaluation_config={\n",
    "        \"type\": \"similarity\",\n",
    "        \"test_dataset\": \"rag_test_data_lilianweng_gpt-4o_1721032414.736622.csv\",\n",
    "        \"evaluator_kwargs\": {\n",
    "            \"top_k\": 3,\n",
    "            \"relevance_threshold\": 0.2,   # Minimum relevance to consider for scoring\n",
    "            \"position_weights\": [1.0, 0.5, 0.3]  # More weight to top results\n",
    "        }\n",
    "    },\n",
    "    database_logging=True,\n",
    "    database_path=\"eval.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run only the data-ingestion related optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting Data Ingestion Optimization...</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting Data Ingestion Optimization\u001b[0m\u001b[1;38;5;27m...\u001b[0m\u001b[92m ─────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:29:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Overwriting existing study: lillog_agents_study                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:29:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Overwriting existing study: lillog_agents_study                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:27,421] A new study created in RDB with name: lillog_agents_study\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601e6090540b476693de9a9987a50fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782136410c114cb897d051baa940b961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.6994</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.6994\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:36,421] Trial 0 finished with value: 0.6993674072954389 and parameters: {'document_loader_index': 2, 'chunk_size': 500}. Best is trial 0 with value: 0.6993674072954389.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fb606667b7440a87b9e5d498cc7d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7543</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7543\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:40,881] Trial 1 finished with value: 0.7543484701703952 and parameters: {'document_loader_index': 2, 'chunk_size': 3000}. Best is trial 1 with value: 0.7543484701703952.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f3bfc011174be5889b5b4793b4149f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7606</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7606\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:45,793] Trial 2 finished with value: 0.7606029867262851 and parameters: {'document_loader_index': 1, 'chunk_size': 1500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56df9584c3e84e469ce82f9c9054aa3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.6950</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.6950\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:54,125] Trial 3 finished with value: 0.6949703637441452 and parameters: {'document_loader_index': 0, 'chunk_size': 500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fc5e3fbd154616baf0459f35aa4dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7509</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7509\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:29:59,009] Trial 4 finished with value: 0.7509295219266461 and parameters: {'document_loader_index': 2, 'chunk_size': 1500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">5</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m5\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90a59c0ada84e45b3834e2d139a7854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7083</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7083\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:07,339] Trial 5 finished with value: 0.7083337836795384 and parameters: {'document_loader_index': 1, 'chunk_size': 500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">6</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m6\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:30:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7606029867262851</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:30:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.7606029867262851\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:07,363] Trial 6 finished with value: 0.7606029867262851 and parameters: {'document_loader_index': 1, 'chunk_size': 1500}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">7</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m7\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84faae65d7424d4c83931b10d368a952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7347</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7347\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:13,127] Trial 7 finished with value: 0.7347048121641531 and parameters: {'document_loader_index': 1, 'chunk_size': 1000}. Best is trial 2 with value: 0.7606029867262851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">8</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m8\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef0dd78ee794d8fb5be99781a97b848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Trial Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7669</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTrial Score:\u001b[0m \u001b[1;96m0.7669\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:17,423] Trial 8 finished with value: 0.7669465389795974 and parameters: {'document_loader_index': 1, 'chunk_size': 3000}. Best is trial 8 with value: 0.7669465389795974.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m9\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:30:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config already evaluated with score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7543484701703952</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:30:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config already evaluated with score: \u001b[1;36m0.7543484701703952\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:30:17,452] Trial 9 finished with value: 0.7543484701703952 and parameters: {'document_loader_index': 2, 'chunk_size': 3000}. Best is trial 8 with value: 0.7669465389795974.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Optimization Complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mOptimization Complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.7669</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Best Parameters:</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">'document_loader'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">&lt;ParserType.UNSTRUCTURED:</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">'unstructured'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">&gt;</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">'chunk_size'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">3000</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m0.7669\u001b[0m\n",
       "\u001b[32mBest Parameters:\u001b[0m\n",
       "\u001b[1;96m{\u001b[0m\u001b[96m'document_loader'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m<\u001b[0m\u001b[1;96mParserType.UNSTRUCTURED:\u001b[0m\u001b[96m \u001b[0m\u001b[96m'unstructured'\u001b[0m\u001b[1;96m>\u001b[0m\u001b[96m, \u001b[0m\u001b[96m'chunk_size'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m3000\u001b[0m\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6b87dfc5484d4cad754c45469ae4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Loading graph...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mLoading graph\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:18<00:00,  5.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Successfully optimized and cached best configuration</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Successfully optimized and cached best configuration\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataIngestResults(best_config=DataIngestConfig(input_source='lillog_agents.pdf', document_loader=LoaderConfig(type=<ParserType.UNSTRUCTURED: 'unstructured'>, loader_kwargs=None, custom_class=None), chunking_strategy=ChunkingStrategyConfig(type=<ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, chunker_kwargs={'separators': ['\\n\\n', '\\n', ' ', '']}, custom_class=None), chunk_size=3000, chunk_overlap=100, embedding_model=EmbeddingConfig(type=<EmbeddingType.AZURE_OPENAI: 'azure_openai'>, model_kwargs={'model': 'text-embedding-3-large'}, custom_class=None), vector_database=VectorDBConfig(type=<VectorDatabase.CHROMA: 'chroma'>, vectordb_kwargs={'persist_directory': 'chroma_sample2123/9', 'collection_metadata': {'hnsw:space': 'cosine'}}, custom_class=None), sampling_rate=None), best_score=0.7669465389795974, best_pipeline=<ragbuilder.data_ingest.pipeline.DataIngestPipeline object at 0x56a02c740>, n_trials=10, completed_trials=10, optimization_time=50.021133, avg_latency=349.08733333333333, error_rate=0.0, best_index=<langchain_community.vectorstores.chroma.Chroma object at 0x377fc0a40>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_builder.optimize_data_ingest(data_ingest_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We now have an optimized vector store with optimized retrievability. \n",
    "Now let's proceed to define the retrieval options config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_config = RetrievalOptionsConfig(\n",
    "    retrievers=[\n",
    "        {\n",
    "            \"type\": \"vector_similarity\", # Vector similarity search\n",
    "            \"retriever_k\": [20],\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"bm25\",  # BM25 keyword search retriever\n",
    "            \"retriever_k\": [20],\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"parent_doc_large\", # Parent doc retriever with large chunks as parent docs\n",
    "            \"retriever_k\": [20],\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"graph\",  # Graph retriever using the knowledge graph\n",
    "            \"retriever_k\": [20],\n",
    "            \"weight\": 0.25\n",
    "        }\n",
    "    ],\n",
    "    rerankers=[\n",
    "        {\"type\": \"BAAI/bge-reranker-base\"},\n",
    "        {\"type\": \"mixedbread-ai/mxbai-rerank-large-v1\"}\n",
    "    ],\n",
    "    top_k=[3, 5, 10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:32:30] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736622.</span>csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:32:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.\u001b[1;36m736622.\u001b[0mcsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting retriever optimization...</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting retriever optimization\u001b[0m\u001b[1;38;5;27m...\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:32:30,424] A new study created in RDB with name: retriever_1735664550667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80b73db2e4e4f8f8a7ff2914f7d9434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model mixedbread-ai/mxbai-rerank-large-v1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535dd16cc84949c5adccd47cbadf45e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.979</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.958</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m0.979\u001b[0m\n",
       "Context Precision: \u001b[1;36m0.958\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:02,285] Trial 0 finished with value: 0.9787234042476052 and parameters: {'n_retrievers': 3, 'retriever_0_index': 2, 'retriever_1_index': 1, 'retriever_2_index': 3, 'use_rerankers': True, 'reranker_index': 1, 'final_k': 10}. Best is trial 0 with value: 0.9787234042476052.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model mixedbread-ai/mxbai-rerank-large-v1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28abffccecc44550b9e13bc29286eb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:17,136] Trial 1 finished with value: 0.9999999999805556 and parameters: {'n_retrievers': 3, 'retriever_0_index': 1, 'retriever_1_index': 1, 'retriever_2_index': 3, 'use_rerankers': True, 'reranker_index': 1, 'final_k': 3}. Best is trial 1 with value: 0.9999999999805556.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589fa80c293c495d839bc488c58cd8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:22,825] Trial 2 finished with value: 0.9999999999736111 and parameters: {'n_retrievers': 2, 'retriever_0_index': 1, 'retriever_1_index': 1, 'use_rerankers': False, 'final_k': 10}. Best is trial 1 with value: 0.9999999999805556.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea87d67e6444af5a6d45c5943ac07e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:35,182] Trial 3 finished with value: 0.9999999999833333 and parameters: {'n_retrievers': 3, 'retriever_0_index': 1, 'retriever_1_index': 3, 'retriever_2_index': 0, 'use_rerankers': True, 'reranker_index': 0, 'final_k': 3}. Best is trial 3 with value: 0.9999999999833333.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1a8f2ff1d44f99980a3450215661f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Average Score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.000</span>\n",
       "Context Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "Context Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mAverage Score: \u001b[0m\u001b[1;32m1.000\u001b[0m\n",
       "Context Precision: \u001b[1;36m1.000\u001b[0m\n",
       "Context Recall: \u001b[1;36m1.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 22:33:45,328] Trial 4 finished with value: 0.9999999999805556 and parameters: {'n_retrievers': 1, 'retriever_0_index': 2, 'use_rerankers': True, 'reranker_index': 0, 'final_k': 3}. Best is trial 3 with value: 0.9999999999833333.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Creating retrievers...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCreating retrievers\u001b[0m\u001b[2;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TransformerRanker model BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Pipeline execution complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Pipeline execution complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">✓ Optimization complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27m✓ Optimization complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">1.0000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m1.0000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Configuration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'retrievers'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'bm25'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'graph'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'vector_similarity'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">]</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'top_k'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'rerankers'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'BAAI/bge-reranker-base'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">]}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;96m{\u001b[0m\u001b[32m'retrievers'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m[\u001b[0m\u001b[32m'bm25'\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'graph'\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'vector_similarity'\u001b[0m\u001b[1;96m]\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'top_k'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[96m, \u001b[0m\u001b[32m'rerankers'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;96m[\u001b[0m\u001b[32m'BAAI/bge-reranker-base'\u001b[0m\u001b[1;96m]\u001b[0m\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RetrievalResults(best_config=RetrievalConfig(retrievers=[BaseRetrieverConfig(type=<RetrieverType.BM25: 'bm25'>, retriever_kwargs={}, custom_class=None, retriever_k=[20], weight=0.25), BaseRetrieverConfig(type=<RetrieverType.GRAPH_RETRIEVER: 'graph'>, retriever_kwargs={}, custom_class=None, retriever_k=[20], weight=0.25), BaseRetrieverConfig(type=<RetrieverType.VECTOR_SIMILARITY: 'vector_similarity'>, retriever_kwargs={}, custom_class=None, retriever_k=[20], weight=0.25)], rerankers=[RerankerConfig(type=<RerankerType.BGE_BASE: 'BAAI/bge-reranker-base'>, reranker_kwargs={}, custom_class=None)], top_k=3), best_score=0.9999999999833333, best_pipeline=<ragbuilder.retriever.pipeline.RetrieverPipeline object at 0x307f1ad80>, n_trials=5, completed_trials=5, optimization_time=74.894355, avg_latency=1613.4706666666668, error_rate=0.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_builder.optimize_retrieval(retrieval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'lillog_agents.pdf', 'relevance_score': 1.8486328125}, page_content=\"experiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\"),\n",
       " Document(metadata={'source': 'lillog_agents.pdf', 'vector_score': 0.5687193870544434, 'type': 'primary', 'relevance_score': 1.509765625}, page_content='[Vector Search Result - Score: 0.569]\\nexperiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil\\'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nRelated Documents:\\n\\n[Graph-Connected Document - Score: 0.848]\\nConnection Paths:\\n- Concept \\'Sensorymemory\\' → Concept \\'Shorttermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Longtermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Longtermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Sensorymemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Explicitmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Shorttermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Sensorymemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Shorttermmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Longtermmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Sensorymemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Explicitmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Shorttermmemory\\' (1 hops, 2 shared entities)\\nDocument text: into a neural network by performing behavioral cloning over actions. The history data is generated\\n\\nby a set of source policies, each trained for a specific task. At the training stage, during each RL\\n\\nrun, a random task is sampled and a subsequence of multi-episode history is used for training,\\n\\nsuch that the learned policy is task-agnostic.\\n\\nIn reality, the model has limited context window length, so episodes should be short enough to\\n\\nconstruct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a\\n\\nnear-optimal in-context RL algorithm. The emergence of in-context RL requires long enough\\n\\ncontext.\\n\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert\\n\\ntrajectories instead of learning history), source policy (used for generating trajectories for\\n\\ndistillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD\\n\\ndemonstrates in-context RL with performance getting close to RL^2 despite only using offline RL\\n\\nand learns much faster than other baselines. When conditioned on partial training history of the\\n\\nsource policy, AD also improves much faster than ED baseline.\\n\\nLil\\'Log\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze. (Image source: Laskin et al. 2023)\\n\\nComponent Two: Memory\\n\\n(Big thank you to ChatGPT for helping me draft this section. Iʼve learned a lot about the human\\n\\nbrain and data structure for fast MIPS in my conversations with ChatGPT.)\\n\\nTypes of Memory\\n\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve\\n\\ninformation. There are several types of memory in human brains.\\n\\n\\x00. Sensory Memory: This is the earliest stage of memory, providing the ability to retain\\n\\nimpressions of sensory information (visual, auditory, etc) after the original stimuli have ended.\\n\\nSensory memory typically only lasts for up to a few seconds. Subcategories include iconic\\n\\nmemory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\x00. Short-Term Memory (STM) or Working Memory: It stores information that we are currently\\n\\naware of and needed to carry out complex cognitive tasks such as learning and reasoning.\\n\\nShort-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for\\n\\n20-30 seconds.\\n\\n\\x00. Long-Term Memory (LTM): Long-term memory can store information for a remarkably long\\n\\ntime, ranging from a few days to decades, with an essentially unlimited storage capacity. There\\n\\nare two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those\\n\\nmemories that can be consciously recalled, including episodic memory (events and\\n\\nexperiences) and semantic memory (facts and concepts).\\n\\n[Graph-Connected Document - Score: 0.728]\\nConnection Paths:\\n- Concept \\'Faiss\\' → Architecture \\'Mrkl\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Model \\'Talm\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Tool \\'Chatgpt Plugins\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Model \\'Toolformer\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Algorithm \\'Scann\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Tool \\'Openai Api\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Algorithm \\'Faiss\\' (2 hops, 2 shared entities)\\nDocument text: space, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nclustering of data points. FAISS applies vector quantization by partitioning the vector space into\\n\\nclusters and then refining the quantization within clusters. Search first looks for cluster\\n\\ncandidates with coarse quantization and then further looks into each cluster with finer\\n\\nquantization.\\n\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector ~xi\\n\\nxi\\n\\n⟨q, xi⟩\\n\\nquantization. It quantizes a data point\\n\\nto\\n\\nsuch that the inner product\\n\\nis as similar to\\n\\n∠q, ~xi\\n\\nthe original distance of\\n\\nas possible, instead of picking the closet quantization centroid\\n\\npoints.\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\n\\nComponent Three: Tool Use\\n\\nLil\\'Log\\n\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and\\n\\nutilize external objects to do things that go beyond our physical and cognitive limits. Equipping\\n\\nLLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-\\n\\nsymbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection\\n\\nof “expert” modules and the general-purpose LLM works as a router to route inquiries to the best\\n\\nsuitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g.\\n\\nmath calculator, currency converter, weather API).\\n\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case.\\n\\nTheir experiments showed that it was harder to solve verbal math problems than explicitly stated\\n\\nmath problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for\\n\\nthe basic arithmetic reliably. The results highlight when the external symbolic tools can work\\n\\nreliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\n\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al.\\n\\n2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether\\n\\na newly added API call annotation can improve the quality of model outputs. See more details in the\\n\\n“External APIs” section of Prompt Engineering.\\n\\nChatGPT Plugins and OpenAI API function calling are good examples of LLMs augmented with tool\\n\\nuse capability working in practice. The collection of tool APIs can be provided by other developers\\n\\n(as in Plugins) or self-defined (as in function calls).\\n\\n[Graph-Connected Document - Score: 0.728]\\nConnection Paths:\\n- Concept \\'Sensorymemory\\' → Concept \\'Agent System Overview\\' (2 hops, 2 shared entities)\\nDocument text: Lil\\'Log\\n\\nPosts\\n\\nArchive\\n\\nSearch\\n\\nTags\\n\\nLLM Powered Autonomous Agents\\n\\nDate: June 23, 2023 | Estimated Reading Time: 31 min | Author: Lilian Weng\\n\\nTable of Contents\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several\\n\\nproof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring\\n\\nexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays\\n\\nand programs; it can be framed as a powerful general problem solver.\\n\\nAgent System Overview\\n\\nIn a LLM-powered autonomous agent system, LLM functions as the agentʼs brain, complemented\\n\\nby several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable\\n\\nsubgoals, enabling efficient handling of complex tasks.\\n\\nReflection and refinement: The agent can do self-criticism and self-reflection over past\\n\\nactions, learn from mistakes and refine them for future steps, thereby improving the quality of\\n\\nfinal results.\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as\\n\\nutilizing short-term memory of the model to learn.\\n\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite)\\n\\ninformation over extended periods, often by leveraging an external vector store and fast\\n\\nretrieval.\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model\\n\\nweights (often hard to change after pre-training), including current information, code\\n\\nexecution capability, access to proprietary information sources and more.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\n\\nA complicated task usually involves many steps. An agent needs to know what they are and plan\\n\\nahead.\\n\\nFAQ emojisearch.app\\n\\nLil\\'Log\\n\\nTask Decomposition\\n\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for\\n\\nenhancing model performance on complex tasks. The model is instructed to “think step by step” to\\n\\nutilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT\\n\\ntransforms big tasks into multiple manageable tasks and shed lights into an interpretation of the\\n\\nmodelʼs thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at\\n\\neach step. It first decomposes the problem into multiple thought steps and generates multiple\\n\\nthoughts per step, creating a tree structure. The search process can be BFS (breadth-first search)\\n\\nor DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\n\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\" ,\\n\\n\"What are the subgoals for achieving XYZ?\" , (2) by using task-specific instructions; e.g. \"Write\\n\\na story outline.\" for writing a novel, or (3) with human inputs.\\n'),\n",
       " Document(metadata={'doc_id': 'ff8d7684-c176-403e-b71d-b0c9bca1af7f', 'source': 'lillog_agents.pdf', 'relevance_score': -0.53515625}, page_content=\"happens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nclustering of data points. FAISS applies vector quantization by partitioning the vector space into\\n\\nclusters and then refining the quantization within clusters. Search first looks for cluster\\n\\ncandidates with coarse quantization and then further looks into each cluster with finer\\n\\nquantization.\\n\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector ~xi\\n\\nxi\\n\\n⟨q, xi⟩\\n\\nquantization. It quantizes a data point\\n\\nto\\n\\nsuch that the inner product\\n\\nis as similar to\\n\\n∠q, ~xi\\n\\nthe original distance of\\n\\nas possible, instead of picking the closet quantization centroid\\n\\npoints.\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\n\\nComponent Three: Tool Use\\n\\nLil'Log\\n\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and\\n\\nutilize external objects to do things that go beyond our physical and cognitive limits. Equipping\\n\\nLLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-\\n\\nsymbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection\\n\\nof “expert” modules and the general-purpose LLM works as a router to route inquiries to the best\\n\\nsuitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g.\\n\\nmath calculator, currency converter, weather API).\")]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_builder.optimized_retriever.invoke(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have an optimized retrieval setup with optimized F1 score (Precision & recall).\n",
    "\n",
    "Now let's proceed to define the LLM generation options config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragbuilder.config.base import LLMConfig\n",
    "\n",
    "gen_config = GenerationOptionsConfig(\n",
    "    llms = [\n",
    "        LLMConfig(type=\"azure_openai\", model_kwargs={'model':'gpt-4o-mini', 'temperature':0.2}),\n",
    "        LLMConfig(type=\"azure_openai\", model_kwargs={'model':'gpt-4o', 'temperature':0.2}),\n",
    "    ],\n",
    "    optimization={\n",
    "        \"n_trials\": 12, \n",
    "        \"n_jobs\": 1,\n",
    "        \"study_name\": \"lillog_agents_study\",\n",
    "        \"optimization_direction\": \"maximize\"\n",
    "    },\n",
    "    evaluation_config={\"type\": \"ragas\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:34:58] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736622.</span>csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:34:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Reusing test dataset from data ingestion: rag_test_data_lilianweng_gpt-4o_1721032414.\u001b[1;36m736622.\u001b[0mcsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Starting Generation Optimization</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0m\u001b[1;38;5;27mStarting Generation Optimization\u001b[0m\u001b[92m ─────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> trial configurations                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generated \u001b[1;36m12\u001b[0m trial configurations                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">0</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m0\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m0\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m0\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">1</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m1\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m1\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m1\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">2</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m2\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m2\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m2\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">3</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m3\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m3\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m3\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">4</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m4\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m4\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m4\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">5</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m5\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m5\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m5\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">6</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m6\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m6\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m6\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">7</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m7\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m7\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m7\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">8</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m8\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m8\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m8\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">9</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m9\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m9\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m9\u001b[0m                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">10</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m10\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m10\u001b[0m                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m10\u001b[0m                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">Trial </span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">/</span><span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;27mTrial \u001b[0m\u001b[1;38;5;27m11\u001b[0m\u001b[1;38;5;27m/\u001b[0m\u001b[1;38;5;27m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:37:06] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating pipeline for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:37:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating pipeline for trial \u001b[1;36m11\u001b[0m                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing eval dataset for trial <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing eval dataset for trial \u001b[1;36m11\u001b[0m                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49efb3be4618432aab842ff43ce5d32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:37:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Evaluating prompt results                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:37:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Evaluating prompt results                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f08a0bd96714a0389ff80d1a2c8e6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:38:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Calculating final prompt testing results                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:38:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Calculating final prompt testing results                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Average correctness results saved to <span style=\"color: #008000; text-decoration-color: #008000\">'rag_average_correctness_20241231_223853.csv'</span>             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Average correctness results saved to \u001b[32m'rag_average_correctness_20241231_223853.csv'\u001b[0m             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Optimization Complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mOptimization Complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Score:</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">0.8154</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Score:\u001b[0m \u001b[1;96m0.8154\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Best Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mBest Configuration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'LLMType.AZURE_OPENAI:gpt-4o'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">,</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">,</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_template'</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a helpful assistant. Answer any questions solely based on the context provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">below. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">know.\"\\n\\n&lt;context&gt;\\n{context}\\n&lt;/context&gt;\\n'</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;96m{\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'model'\u001b[0m\u001b[96m: \u001b[0m\u001b[32m'LLMType.AZURE_OPENAI:gpt-4o'\u001b[0m\u001b[96m,\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'temperature'\u001b[0m\u001b[96m: \u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[96m,\u001b[0m\n",
       "\u001b[96m    \u001b[0m\u001b[32m'prompt_template'\u001b[0m\u001b[96m: \u001b[0m\u001b[32m'You are a helpful assistant. Answer any questions solely based on the context provided \u001b[0m\n",
       "\u001b[32mbelow. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t \u001b[0m\n",
       "\u001b[32mknow.\"\\n\\n\u001b[0m\u001b[32m<\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m>\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n</context\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n'\u001b[0m\n",
       "\u001b[1;96m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GenerationResults(best_config=GenerationConfig(llm=LLMConfig(type=<LLMType.AZURE_OPENAI: 'azure_openai'>, model_kwargs={'model': 'gpt-4o', 'temperature': 0.2}), prompt_template='You are a helpful assistant. Answer any questions solely based on the context provided below. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t know.\"\\n\\n<context>\\n{context}\\n</context>\\n', prompt_key='default_informative'), best_score=0.8154456849114275, best_pipeline={\n",
       "  context: ContextualCompressionRetriever(base_compressor=DocumentCompressorPipeline(transformers=[RerankerLangChainCompressor(model=<rerankers.models.transformer_ranker.TransformerRanker object at 0x569de2480>, kwargs={}, k=3)]), base_retriever=EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x56a0d2fc0>), Neo4jGraphRetriever(graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x3744347a0>, embeddings=AzureOpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x377e238f0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x377e22420>, model='text-embedding-3-large', dimensions=None, deployment=None, openai_api_version='2024-02-01', openai_api_base=None, openai_api_type='azure', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=2048, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True, azure_endpoint='https://krux-azure-oai-003.openai.azure.com/', azure_ad_token=None, azure_ad_token_provider=None, validate_base_url=True), top_k=20, max_hops=2, max_related_docs_per_doc=3, graph_weight=0.3, index_name='document_embeddings'), VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x377fc0a40>, search_kwargs={'k': 20})], weights=[0.3333333333333333, 0.3333333333333333, 0.3333333333333333])),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| RunnableAssign(mapper={\n",
       "    context: RunnableLambda(itemgetter('context'))\n",
       "             | RunnableLambda(format_docs)\n",
       "  })\n",
       "| RunnableAssign(mapper={\n",
       "    answer: ChatPromptTemplate(input_variables=['context', 'question'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='You are a helpful assistant. Answer any questions solely based on the context provided below. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t know.\"\\n\\n<context>\\n{context}\\n</context>\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}')), MessagesPlaceholder(variable_name='chat_history', optional=True)])\n",
       "            | AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x16534d970>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x165241fd0>, model_name='gpt-4o', temperature=0.2, openai_api_key=SecretStr('**********'), openai_proxy='', azure_endpoint='https://krux-azure-oai-003.openai.azure.com/', openai_api_version='2024-02-01', openai_api_type='azure')\n",
       "            | StrOutputParser()\n",
       "  })\n",
       "| RunnablePick(keys=['answer', 'context']), n_trials=12, completed_trials=12, optimization_time=234.716064, avg_latency=None, error_rate=None, best_prompt='You are a helpful assistant. Answer any questions solely based on the context provided below. \\nIf the provided context does not have the relevant facts to answer the question, say \"I don\\'t know.\"\\n\\n<context>\\n{context}\\n</context>\\n')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_builder.optimize_generation(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_results = adv_builder.optimization_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = adv_results.invoke(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is HNSW?\n",
      "Answer: HNSW (Hierarchical Navigable Small World) is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps, such as the “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {response['question']}\\nAnswer: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_ingest\": {\n",
      "    \"score\": 0.7669465389795974,\n",
      "    \"optimization_time\": 50.021133,\n",
      "    \"config\": {\n",
      "      \"document_loader\": \"unstructured\",\n",
      "      \"chunking_strategy\": \"RecursiveCharacterTextSplitter\",\n",
      "      \"chunk_size\": 3000,\n",
      "      \"chunk_overlap\": 100,\n",
      "      \"embedding_model\": \"EmbeddingType.AZURE_OPENAI:text-embedding-3-large\",\n",
      "      \"vector_database\": \"chroma\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": 349.08733333333333,\n",
      "      \"error_rate\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"retrieval\": {\n",
      "    \"score\": 0.9999999999833333,\n",
      "    \"optimization_time\": 74.894355,\n",
      "    \"config\": {\n",
      "      \"retrievers\": [\n",
      "        \"bm25\",\n",
      "        \"graph\",\n",
      "        \"vector_similarity\"\n",
      "      ],\n",
      "      \"top_k\": 3,\n",
      "      \"rerankers\": [\n",
      "        \"BAAI/bge-reranker-base\"\n",
      "      ]\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": 1613.4706666666668,\n",
      "      \"error_rate\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"generation\": {\n",
      "    \"score\": 0.8154456849114275,\n",
      "    \"optimization_time\": 234.716064,\n",
      "    \"config\": {\n",
      "      \"model\": \"LLMType.AZURE_OPENAI:gpt-4o\",\n",
      "      \"temperature\": 0.2,\n",
      "      \"prompt_template\": \"You are a helpful assistant. Answer any questions solely based on the context provided below. \\nIf the provided context does not have the relevant facts to answer the question, say \\\"I don't know.\\\"\\n\\n<context>\\n{context}\\n</context>\\n\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"avg_latency\": null,\n",
      "      \"error_rate\": null\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(adv_results.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access individual module components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'doc_id': 'b841a780-cbf5-40fc-9921-029b8ba33b8b', 'source': 'lillog_agents.pdf'}, page_content=\"Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic\\n\\nmemory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\x00. Short-Term Memory (STM) or Working Memory: It stores information that we are currently\\n\\naware of and needed to carry out complex cognitive tasks such as learning and reasoning.\\n\\nShort-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for\\n\\n20-30 seconds.\\n\\n\\x00. Long-Term Memory (LTM): Long-term memory can store information for a remarkably long\\n\\ntime, ranging from a few days to decades, with an essentially unlimited storage capacity. There\\n\\nare two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those\\n\\nmemories that can be consciously recalled, including episodic memory (events and\\n\\nexperiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\"),\n",
       "  0.19332719635195306),\n",
       " (Document(metadata={'doc_id': '61ef51b5-89c0-467c-bbb7-8f72163e1d39', 'source': 'lillog_agents.pdf'}, page_content=\"Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic\\n\\nmemory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\x00. Short-Term Memory (STM) or Working Memory: It stores information that we are currently\\n\\naware of and needed to carry out complex cognitive tasks such as learning and reasoning.\\n\\nShort-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for\\n\\n20-30 seconds.\\n\\n\\x00. Long-Term Memory (LTM): Long-term memory can store information for a remarkably long\\n\\ntime, ranging from a few days to decades, with an essentially unlimited storage capacity. There\\n\\nare two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those\\n\\nmemories that can be consciously recalled, including episodic memory (events and\\n\\nexperiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\"),\n",
       "  0.19332719635195306),\n",
       " (Document(metadata={'doc_id': 'f022355b-e04a-4137-9d8a-82493f908301', 'source': 'lillog_agents.pdf'}, page_content=\"Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and\\n\\nshould be stopped. Inefficient planning refers to trajectories that take too long without success.\\n\\nHallucination is defined as encountering a sequence of consecutive identical actions that lead to\\n\\nthe same observation in the environment.\\n\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of\\n\\n(failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added\\n\\ninto the agentʼs working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\n\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by\\n\\nexplicitly presenting it with a sequence of past outputs, each annotated with feedback. Human\\n\\nDh = {(x, yi, ri, zi)}n yi\\n\\nfeedback data is a collection of\\n\\nri\\n\\nzi\\n\\nmodel completion,\\n\\nis the human rating of\\n\\n, and\\n\\nx\\n\\nyi\\n\\n, where\\n\\nis the prompt, each\\n\\ni=1 is the corresponding human-provided\\n\\nis a\\n\\nhindsight feedback. Assume the feedback tuples are ranked by reward,\\n\\nrn ≥ rn−1 ≥ ⋯ ≥ r1\\n\\nprocess is supervised fine-tuning where the data is a sequence in the form of yn τh = (x, zi, yi, zj, yj, … , zn, yn) where conditioned on the sequence prefix, such that the model can self-reflect to produce better\\n\\n≤ i ≤ j ≤ n\\n\\n, where\\n\\n. The model is finetuned to only predict\\n\\noutput based on the feedback sequence. The model can optionally receive multiple rounds of\\n\\ninstructions with human annotators at test time.\\n\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-\\n\\ntraining dataset. To avoid shortcutting and copying (because there are many common words in\\n\\nfeedback sequences), they randomly mask 0% - 5% of past tokens during training.\\n\\nThe\\n\\nLil'Log\\n\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization\\n\\nfrom human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\n\\nThe idea of CoH is to present a history of sequentially improved outputs in context and train the\\n\\nmodel to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al.\\n\\n2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where\\n\\nan algorithm is encapsulated in a long history-conditioned policy. Considering that an agent\\n\\ninteracts with the environment many times and in each episode the agent gets a little better, AD\\n\\nconcatenates this learning history and feeds that into the model. Hence we should expect the next\"),\n",
       "  0.16912849177876454),\n",
       " (Document(metadata={'doc_id': '0361daf6-20c6-4d27-8829-78f05e155279', 'source': 'lillog_agents.pdf'}, page_content=\"Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and\\n\\nshould be stopped. Inefficient planning refers to trajectories that take too long without success.\\n\\nHallucination is defined as encountering a sequence of consecutive identical actions that lead to\\n\\nthe same observation in the environment.\\n\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of\\n\\n(failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added\\n\\ninto the agentʼs working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\n\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by\\n\\nexplicitly presenting it with a sequence of past outputs, each annotated with feedback. Human\\n\\nDh = {(x, yi, ri, zi)}n yi\\n\\nfeedback data is a collection of\\n\\nri\\n\\nzi\\n\\nmodel completion,\\n\\nis the human rating of\\n\\n, and\\n\\nx\\n\\nyi\\n\\n, where\\n\\nis the prompt, each\\n\\ni=1 is the corresponding human-provided\\n\\nis a\\n\\nhindsight feedback. Assume the feedback tuples are ranked by reward,\\n\\nrn ≥ rn−1 ≥ ⋯ ≥ r1\\n\\nprocess is supervised fine-tuning where the data is a sequence in the form of yn τh = (x, zi, yi, zj, yj, … , zn, yn) where conditioned on the sequence prefix, such that the model can self-reflect to produce better\\n\\n≤ i ≤ j ≤ n\\n\\n, where\\n\\n. The model is finetuned to only predict\\n\\noutput based on the feedback sequence. The model can optionally receive multiple rounds of\\n\\ninstructions with human annotators at test time.\\n\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-\\n\\ntraining dataset. To avoid shortcutting and copying (because there are many common words in\\n\\nfeedback sequences), they randomly mask 0% - 5% of past tokens during training.\\n\\nThe\\n\\nLil'Log\\n\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization\\n\\nfrom human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\n\\nThe idea of CoH is to present a history of sequentially improved outputs in context and train the\\n\\nmodel to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al.\\n\\n2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where\\n\\nan algorithm is encapsulated in a long history-conditioned policy. Considering that an agent\\n\\ninteracts with the environment many times and in each episode the agent gets a little better, AD\\n\\nconcatenates this learning history and feeds that into the model. Hence we should expect the next\"),\n",
       "  0.16912849177876454)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_results.data_ingest.best_index.similarity_search_with_relevance_scores(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'lillog_agents.pdf', 'relevance_score': 1.8486328125}, page_content=\"experiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\"),\n",
       " Document(metadata={'source': 'lillog_agents.pdf', 'vector_score': 0.5687193870544434, 'type': 'primary', 'relevance_score': 1.509765625}, page_content='[Vector Search Result - Score: 0.569]\\nexperiences) and semantic memory (facts and concepts).\\n\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and\\n\\nroutines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\nFig. 8. Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or\\n\\nother modalities;\\n\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite\\n\\ncontext window length of Transformer.\\n\\nLong-term memory as the external vector store that the agent can attend to at query time,\\n\\naccessible via fast retrieval.\\n\\nLil\\'Log\\n\\nMaximum Inner Product Search (MIPS)\\n\\nThe external memory can alleviate the restriction of finite attention span. A standard practice is to\\n\\nsave the embedding representation of information into a vector store database that can support\\n\\nfast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is\\n\\nthe approximate nearest neighbors (ANN) algorithm to return approximately top k nearest\\n\\nneighbors to trade off a little accuracy lost for a huge speedup.\\n\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items\\n\\nare mapped to the same buckets with high probability, where the number of buckets is much\\n\\nsmaller than the number of inputs.\\n\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random\\n\\nprojection trees, a set of binary trees where each non-leaf node represents a hyperplane\\n\\nsplitting the input space into half and each leaf stores one data point. Trees are built\\n\\nindependently and at random, so to some extent, it mimics a hashing function. ANNOY search\\n\\nhappens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nRelated Documents:\\n\\n[Graph-Connected Document - Score: 0.848]\\nConnection Paths:\\n- Concept \\'Sensorymemory\\' → Concept \\'Shorttermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Longtermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Longtermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Sensorymemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Explicitmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Shorttermmemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Sensorymemory\\' (2 hops, 3 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Memory\\' (2 hops, 3 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Sensorymemory\\' → Concept \\'Shorttermmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Longtermmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Shorttermmemory\\' → Concept \\'Sensorymemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Explicitmemory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Memory\\' (1 hops, 2 shared entities)\\n- Concept \\'Longtermmemory\\' → Concept \\'Shorttermmemory\\' (1 hops, 2 shared entities)\\nDocument text: into a neural network by performing behavioral cloning over actions. The history data is generated\\n\\nby a set of source policies, each trained for a specific task. At the training stage, during each RL\\n\\nrun, a random task is sampled and a subsequence of multi-episode history is used for training,\\n\\nsuch that the learned policy is task-agnostic.\\n\\nIn reality, the model has limited context window length, so episodes should be short enough to\\n\\nconstruct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a\\n\\nnear-optimal in-context RL algorithm. The emergence of in-context RL requires long enough\\n\\ncontext.\\n\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert\\n\\ntrajectories instead of learning history), source policy (used for generating trajectories for\\n\\ndistillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD\\n\\ndemonstrates in-context RL with performance getting close to RL^2 despite only using offline RL\\n\\nand learns much faster than other baselines. When conditioned on partial training history of the\\n\\nsource policy, AD also improves much faster than ED baseline.\\n\\nLil\\'Log\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze. (Image source: Laskin et al. 2023)\\n\\nComponent Two: Memory\\n\\n(Big thank you to ChatGPT for helping me draft this section. Iʼve learned a lot about the human\\n\\nbrain and data structure for fast MIPS in my conversations with ChatGPT.)\\n\\nTypes of Memory\\n\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve\\n\\ninformation. There are several types of memory in human brains.\\n\\n\\x00. Sensory Memory: This is the earliest stage of memory, providing the ability to retain\\n\\nimpressions of sensory information (visual, auditory, etc) after the original stimuli have ended.\\n\\nSensory memory typically only lasts for up to a few seconds. Subcategories include iconic\\n\\nmemory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\x00. Short-Term Memory (STM) or Working Memory: It stores information that we are currently\\n\\naware of and needed to carry out complex cognitive tasks such as learning and reasoning.\\n\\nShort-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for\\n\\n20-30 seconds.\\n\\n\\x00. Long-Term Memory (LTM): Long-term memory can store information for a remarkably long\\n\\ntime, ranging from a few days to decades, with an essentially unlimited storage capacity. There\\n\\nare two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those\\n\\nmemories that can be consciously recalled, including episodic memory (events and\\n\\nexperiences) and semantic memory (facts and concepts).\\n\\n[Graph-Connected Document - Score: 0.728]\\nConnection Paths:\\n- Concept \\'Faiss\\' → Architecture \\'Mrkl\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Model \\'Talm\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Tool \\'Chatgpt Plugins\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Model \\'Toolformer\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Algorithm \\'Scann\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Tool \\'Openai Api\\' (2 hops, 2 shared entities)\\n- Concept \\'Faiss\\' → Algorithm \\'Faiss\\' (2 hops, 2 shared entities)\\nDocument text: space, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nclustering of data points. FAISS applies vector quantization by partitioning the vector space into\\n\\nclusters and then refining the quantization within clusters. Search first looks for cluster\\n\\ncandidates with coarse quantization and then further looks into each cluster with finer\\n\\nquantization.\\n\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector ~xi\\n\\nxi\\n\\n⟨q, xi⟩\\n\\nquantization. It quantizes a data point\\n\\nto\\n\\nsuch that the inner product\\n\\nis as similar to\\n\\n∠q, ~xi\\n\\nthe original distance of\\n\\nas possible, instead of picking the closet quantization centroid\\n\\npoints.\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\n\\nComponent Three: Tool Use\\n\\nLil\\'Log\\n\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and\\n\\nutilize external objects to do things that go beyond our physical and cognitive limits. Equipping\\n\\nLLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-\\n\\nsymbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection\\n\\nof “expert” modules and the general-purpose LLM works as a router to route inquiries to the best\\n\\nsuitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g.\\n\\nmath calculator, currency converter, weather API).\\n\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case.\\n\\nTheir experiments showed that it was harder to solve verbal math problems than explicitly stated\\n\\nmath problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for\\n\\nthe basic arithmetic reliably. The results highlight when the external symbolic tools can work\\n\\nreliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\n\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al.\\n\\n2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether\\n\\na newly added API call annotation can improve the quality of model outputs. See more details in the\\n\\n“External APIs” section of Prompt Engineering.\\n\\nChatGPT Plugins and OpenAI API function calling are good examples of LLMs augmented with tool\\n\\nuse capability working in practice. The collection of tool APIs can be provided by other developers\\n\\n(as in Plugins) or self-defined (as in function calls).\\n\\n[Graph-Connected Document - Score: 0.728]\\nConnection Paths:\\n- Concept \\'Sensorymemory\\' → Concept \\'Agent System Overview\\' (2 hops, 2 shared entities)\\nDocument text: Lil\\'Log\\n\\nPosts\\n\\nArchive\\n\\nSearch\\n\\nTags\\n\\nLLM Powered Autonomous Agents\\n\\nDate: June 23, 2023 | Estimated Reading Time: 31 min | Author: Lilian Weng\\n\\nTable of Contents\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several\\n\\nproof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring\\n\\nexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays\\n\\nand programs; it can be framed as a powerful general problem solver.\\n\\nAgent System Overview\\n\\nIn a LLM-powered autonomous agent system, LLM functions as the agentʼs brain, complemented\\n\\nby several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable\\n\\nsubgoals, enabling efficient handling of complex tasks.\\n\\nReflection and refinement: The agent can do self-criticism and self-reflection over past\\n\\nactions, learn from mistakes and refine them for future steps, thereby improving the quality of\\n\\nfinal results.\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as\\n\\nutilizing short-term memory of the model to learn.\\n\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite)\\n\\ninformation over extended periods, often by leveraging an external vector store and fast\\n\\nretrieval.\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model\\n\\nweights (often hard to change after pre-training), including current information, code\\n\\nexecution capability, access to proprietary information sources and more.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\n\\nA complicated task usually involves many steps. An agent needs to know what they are and plan\\n\\nahead.\\n\\nFAQ emojisearch.app\\n\\nLil\\'Log\\n\\nTask Decomposition\\n\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for\\n\\nenhancing model performance on complex tasks. The model is instructed to “think step by step” to\\n\\nutilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT\\n\\ntransforms big tasks into multiple manageable tasks and shed lights into an interpretation of the\\n\\nmodelʼs thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at\\n\\neach step. It first decomposes the problem into multiple thought steps and generates multiple\\n\\nthoughts per step, creating a tree structure. The search process can be BFS (breadth-first search)\\n\\nor DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\n\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\" ,\\n\\n\"What are the subgoals for achieving XYZ?\" , (2) by using task-specific instructions; e.g. \"Write\\n\\na story outline.\" for writing a novel, or (3) with human inputs.\\n'),\n",
       " Document(metadata={'doc_id': 'ff8d7684-c176-403e-b71d-b0c9bca1af7f', 'source': 'lillog_agents.pdf', 'relevance_score': -0.53515625}, page_content=\"happens in all the trees to iteratively search through the half that is closest to the query and then\\n\\naggregates the results. The idea is quite related to KD tree but a lot more scalable.\\n\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks\\n\\nwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six\\n\\ndegrees of separation” feature of social networks. HNSW builds hierarchical layers of these\\n\\nsmall-world graphs, where the bottom layers contain the actual data points. The layers in the\\n\\nmiddle create shortcuts to speed up search. When performing a search, HNSW starts from a\\n\\nrandom node in the top layer and navigates towards the target. When it canʼt get any closer, it\\n\\nmoves down to the next layer, until it reaches the bottom layer. Each move in the upper layers\\n\\ncan potentially cover a large distance in the data space, and each move in the lower layers\\n\\nrefines the search quality.\\n\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional\\n\\nspace, distances between nodes follow a Gaussian distribution and thus there should exist\\n\\nclustering of data points. FAISS applies vector quantization by partitioning the vector space into\\n\\nclusters and then refining the quantization within clusters. Search first looks for cluster\\n\\ncandidates with coarse quantization and then further looks into each cluster with finer\\n\\nquantization.\\n\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector ~xi\\n\\nxi\\n\\n⟨q, xi⟩\\n\\nquantization. It quantizes a data point\\n\\nto\\n\\nsuch that the inner product\\n\\nis as similar to\\n\\n∠q, ~xi\\n\\nthe original distance of\\n\\nas possible, instead of picking the closet quantization centroid\\n\\npoints.\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\n\\nComponent Three: Tool Use\\n\\nLil'Log\\n\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and\\n\\nutilize external objects to do things that go beyond our physical and cognitive limits. Equipping\\n\\nLLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-\\n\\nsymbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection\\n\\nof “expert” modules and the general-purpose LLM works as a router to route inquiries to the best\\n\\nsuitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g.\\n\\nmath calculator, currency converter, weather API).\")]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_results.retrieval.invoke(\"What is HNSW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:46:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting RAG server on <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://0.0.0.0:8005</span>                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:46:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting RAG server on \u001b[4;94mhttp://0.0.0.0:8005\u001b[0m                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [3063]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8005 (Press CTRL+C to quit)\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [3063]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# This will return API endpoint\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# localhost:60001/retreive -- retriever only\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# localhost:60001/invoke -- RAG\u001b[39;00m\n",
      "File \u001b[0;32m~/KruxAI/ragbuilder/src/ragbuilder/core/builder.py:433\u001b[0m, in \u001b[0;36mRAGBuilder.serve\u001b[0;34m(self, host, port)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m HTTPException(status_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting RAG server on http://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 433\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mrun(\u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/uvicorn/main.py:577\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    575\u001b[0m         Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m         \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muds \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config\u001b[38;5;241m.\u001b[39muds):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/uvicorn/server.py:65\u001b[0m, in \u001b[0;36mServer.run\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/asyncio/events.py:88\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/asyncio/tasks.py:396\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/asyncio/tasks.py:303\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    301\u001b[0m _enter_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step_run_and_handle_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     _leave_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/uvicorn/server.py:68\u001b[0m, in \u001b[0;36mServer.serve\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserve\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mawait\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/uvicorn/server.py:328\u001b[0m, in \u001b[0;36mServer.capture_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# If we did gracefully shut down due to a signal, try to\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# trigger the expected behaviour now; multiple signals would be\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m captured_signal \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_captured_signals):\n\u001b[0;32m--> 328\u001b[0m     \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_signal\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "builder.serve()\n",
    "# This will return API endpoint\n",
    "# localhost:60001/retreive -- retriever only\n",
    "# localhost:60001/invoke -- RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragbuilder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
